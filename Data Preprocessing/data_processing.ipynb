{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame loaded successfully with correct headers and NaN values!\n",
      "\n",
      "First 5 rows:\n",
      "   First Term Gpa  Second Term Gpa  First Language  Funding  School  \\\n",
      "0        0.000000         0.000000             1.0        2       6   \n",
      "1        2.500000         2.000000             3.0        4       6   \n",
      "2        4.250000         3.923077             1.0        1       6   \n",
      "3        3.020833         2.321429             3.0        4       6   \n",
      "4        4.275000         4.326923             1.0        2       6   \n",
      "\n",
      "   Fast Track  Coop  Residency  Gender  Prev Education  Age Group  \\\n",
      "0           2     1          1       2             1.0        1.0   \n",
      "1           1     2          2       2             1.0        3.0   \n",
      "2           2     1          1       1             2.0        3.0   \n",
      "3           1     2          2       2             2.0        3.0   \n",
      "4           1     1          1       1             2.0        3.0   \n",
      "\n",
      "   High School Average Mark  Math Score  English Grade  First Year Persistence  \n",
      "0                      59.0        16.0            7.0                       1  \n",
      "1                       NaN         NaN            7.0                       1  \n",
      "2                      92.0        41.0            9.0                       1  \n",
      "3                       NaN         NaN            8.0                       1  \n",
      "4                      97.0         NaN            9.0                       1  \n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1437 entries, 0 to 1436\n",
      "Data columns (total 15 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   First Term Gpa            1420 non-null   float64\n",
      " 1   Second Term Gpa           1277 non-null   float64\n",
      " 2   First Language            1326 non-null   float64\n",
      " 3   Funding                   1437 non-null   int64  \n",
      " 4   School                    1437 non-null   int64  \n",
      " 5   Fast Track                1437 non-null   int64  \n",
      " 6   Coop                      1437 non-null   int64  \n",
      " 7   Residency                 1437 non-null   int64  \n",
      " 8   Gender                    1437 non-null   int64  \n",
      " 9   Prev Education            1433 non-null   float64\n",
      " 10  Age Group                 1433 non-null   float64\n",
      " 11  High School Average Mark  694 non-null    float64\n",
      " 12  Math Score                975 non-null    float64\n",
      " 13  English Grade             1392 non-null   float64\n",
      " 14  First Year Persistence    1437 non-null   int64  \n",
      "dtypes: float64(8), int64(7)\n",
      "memory usage: 168.5 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Headers for the CSV file\n",
    "column_names = [\n",
    "    'First Term Gpa',\n",
    "    'Second Term Gpa',\n",
    "    'First Language',\n",
    "    'Funding',\n",
    "    'School',\n",
    "    'Fast Track',\n",
    "    'Coop',\n",
    "    'Residency',\n",
    "    'Gender',\n",
    "    'Prev Education',\n",
    "    'Age Group',\n",
    "    'High School Average Mark',\n",
    "    'Math Score',\n",
    "    'English Grade',\n",
    "    'First Year Persistence'\n",
    "]\n",
    "\n",
    "# File path\n",
    "file_path = '../Data/student_data.csv'\n",
    "\n",
    "# Loading the CSV file into a DataFrame\n",
    "try:\n",
    "    df = pd.read_csv(\n",
    "        file_path,\n",
    "        header=None,          # Telling pandas there is no header row in the file\n",
    "        names=column_names,   # Providing the list of correct column names\n",
    "        na_values='?'         # Telling pandas to treat '?' character as missing (NaN)\n",
    "    )\n",
    "    print(\"DataFrame loaded successfully with correct headers and NaN values!\")\n",
    "\n",
    "    # Displaying the first 5 rows to verify headers and data\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    print(df.head())\n",
    "\n",
    "    # Displaying DataFrame info to verify column names, counts, and Dtypes\n",
    "    print(\"\\nDataFrame Info:\")\n",
    "    print(df.info())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\nError: Could not find the file at {file_path}\")\n",
    "    print(\"Please ensure the file exists and the path is correct.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred while loading the file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data_for_task(predict_persistence, test_size=0.2, random_state=89):\n",
    "  \"\"\"\n",
    "  Splits the DataFrame into training and testing sets for a specific task.\n",
    "\n",
    "  Args:\n",
    "    df (pd.DataFrame): The input DataFrame containing features and targets.\n",
    "                       Assumes '?' has already been replaced with NaN during loading.\n",
    "    predict_persistence (bool): If True, sets 'First Year Persistence' as the target\n",
    "                                and enables stratification. If False, sets\n",
    "                                'Second Term Gpa' as the target and disables\n",
    "                                stratification by default.\n",
    "    test_size (float): The proportion of the dataset to include in the test split.\n",
    "    random_state (int): Controls the shuffling applied to the data before splitting\n",
    "                        for reproducibility.\n",
    "\n",
    "  Returns:\n",
    "    tuple: A tuple containing (X_train, X_test, y_train, y_test) as pandas\n",
    "           DataFrames/Series. Returns None if target column is not found.\n",
    "  \"\"\"\n",
    "\n",
    "  if predict_persistence:\n",
    "    target_column = 'First Year Persistence'\n",
    "    # Ensure target exists before attempting to stratify\n",
    "    if target_column not in df.columns:\n",
    "        print(f\"Error: Target column '{target_column}' not found in DataFrame.\")\n",
    "        return None\n",
    "    stratify_on = df[target_column] # Stratify based on the persistence target\n",
    "  else:\n",
    "    target_column = 'Second Term Gpa'\n",
    "    # Ensure target exists\n",
    "    if target_column not in df.columns:\n",
    "        print(f\"Error: Target column '{target_column}' not found in DataFrame.\")\n",
    "        return None\n",
    "    stratify_on = None # Stratification often not strictly needed for regression\n",
    "\n",
    "  # Define features X (dropping only the chosen target by default)\n",
    "  # Check if target column exists before trying to drop\n",
    "  if target_column in df.columns:\n",
    "      X = df.drop(columns=[target_column])\n",
    "  else:\n",
    "      # Should have been caught above, but added as safeguard\n",
    "      print(f\"Error: Cannot drop non-existent target column '{target_column}'.\")\n",
    "      return None\n",
    "\n",
    "  # Define target y\n",
    "  y = df[target_column]\n",
    "\n",
    "  # Perform the split\n",
    "  try:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "        stratify=stratify_on\n",
    "    )\n",
    "\n",
    "    print(f\"Data split successfully for target: '{target_column}'\")\n",
    "    print(f\"Training set shape: X_train={X_train.shape}, y_train={y_train.shape}\")\n",
    "    print(f\"Test set shape: X_test={X_test.shape}, y_test={y_test.shape}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "  except Exception as e:\n",
    "    print(f\"Error during train_test_split: {e}\")\n",
    "    # This might happen if stratification fails, e.g., due to NaNs in target\n",
    "    # Or if X or y are unexpectedly empty.\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data_for_task(True, test_size=0.2, random_state=89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these might be adjusted inside the function\n",
    "BASE_NUMERICAL_FEATURES = [\n",
    "    'First Term Gpa',\n",
    "    'Second Term Gpa', # Will be excluded if predicting persistence\n",
    "    'High School Average Mark',\n",
    "    'Math Score'\n",
    "]\n",
    "\n",
    "BASE_CAT_NOMINAL_FEATURES = [\n",
    "    'First Language', # Had NaN\n",
    "    'Funding',\n",
    "    'School',         # Only had value 6, OHE will handle this\n",
    "    'Residency',\n",
    "    'Gender',\n",
    "    'Prev Education', # Had NaN (including original 0.0)\n",
    "    'Fast Track',\n",
    "    'Coop'\n",
    "]\n",
    "\n",
    "BASE_CAT_ORDINAL_FEATURES = [\n",
    "    'Age Group',     # Had NaN\n",
    "    'English Grade'  # Had NaN\n",
    "]\n",
    "\n",
    "# Defines the explicit order for ordinal features\n",
    "AGE_GROUP_ORDER = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
    "ENGLISH_GRADE_ORDER = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0]\n",
    "ORDINAL_CATEGORIES = [AGE_GROUP_ORDER, ENGLISH_GRADE_ORDER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_preprocessor(predict_persistence):\n",
    "  \"\"\"\n",
    "  Creates a scikit-learn ColumnTransformer for preprocessing,\n",
    "  adjusting feature lists based on the prediction task.\n",
    "\n",
    "  Args:\n",
    "      predict_persistence (bool): If True, prepares features for persistence\n",
    "                                  prediction (excludes Second Term Gpa).\n",
    "                                  If False, prepares features for GPA prediction.\n",
    "\n",
    "  Returns:\n",
    "      ColumnTransformer: The unfitted preprocessing pipeline structure.\n",
    "  \"\"\"\n",
    "\n",
    "  # --- Dynamically adjusts column lists based on task ---\n",
    "  if predict_persistence:\n",
    "    print(\"Defining preprocessor for Persistence prediction task.\")\n",
    "    # Exclude Second Term Gpa from numerical features\n",
    "    num_features = [col for col in BASE_NUMERICAL_FEATURES if col != 'Second Term Gpa']\n",
    "    cat_nom_features = BASE_CAT_NOMINAL_FEATURES\n",
    "    cat_ord_features = BASE_CAT_ORDINAL_FEATURES\n",
    "    ord_categories = ORDINAL_CATEGORIES\n",
    "    # Exclude First Year Persistence if it exists as a column and predict_persistence is True\n",
    "    # (Should already be excluded when X was created, but as a safeguard)\n",
    "    # cat_nom_features = [col for col in cat_nom_features if col != 'First Year Persistence']\n",
    "\n",
    "  else: # predict_persistence is False (predicting Second Term Gpa)\n",
    "    print(\"Defining preprocessor for Second Term GPA prediction task.\")\n",
    "    # Use all base numerical features\n",
    "    num_features = BASE_NUMERICAL_FEATURES\n",
    "    # Decide if 'First Year Persistence' should be a feature for predicting GPA\n",
    "    # If yes, add it to the categorical list (assuming it's binary 0/1)\n",
    "    include_persistence_as_feature = True # Set to False if you don't want to use it\n",
    "    if include_persistence_as_feature:\n",
    "         # Ensure 'First Year Persistence' isn't already in another list\n",
    "         cat_nom_features = list(set(BASE_CAT_NOMINAL_FEATURES + ['First Year Persistence']))\n",
    "    else:\n",
    "         cat_nom_features = BASE_CAT_NOMINAL_FEATURES\n",
    "\n",
    "    cat_ord_features = BASE_CAT_ORDINAL_FEATURES\n",
    "    ord_categories = ORDINAL_CATEGORIES\n",
    "\n",
    "\n",
    "  # --- Define Preprocessing Steps ---\n",
    "\n",
    "  # Pipeline for numerical features: Impute (median + indicator) then Scale\n",
    "  '''\n",
    "    # Defines the pipeline for numerical features:\n",
    "    # 1. 'imputer': Fills missing values (NaN) using the median calculated from the training data.\n",
    "    #    'add_indicator=True' adds a binary column marking which values were imputed.\n",
    "    # 2. 'scaler': Scales the data (after imputation) to have zero mean and unit variance\n",
    "    # using parameters learned from the training data.\n",
    "  '''\n",
    "  numeric_transformer = Pipeline(steps=[\n",
    "      ('imputer', SimpleImputer(strategy='median', add_indicator=True)),\n",
    "      ('scaler', StandardScaler())\n",
    "  ])\n",
    "\n",
    "  # Pipeline for nominal categorical features: Impute (mode) then OneHotEncode\n",
    "  categorical_transformer_nominal = Pipeline(steps=[\n",
    "      # Impute NaNs using the most frequent value\n",
    "      ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "      # OneHotEncode the categories, ignore unknown categories encountered during transform\n",
    "      ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "  ])\n",
    "\n",
    "  # Pipeline for ordinal categorical features: Impute (mode) then OrdinalEncode\n",
    "  categorical_transformer_ordinal = Pipeline(steps=[\n",
    "      # Impute NaNs using the most frequent value\n",
    "      ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "      # Encode categories ordinally based on predefined order\n",
    "      ('ordinal', OrdinalEncoder(categories=ord_categories, handle_unknown='use_encoded_value', unknown_value=np.nan)), # Handle potential unknowns robustly\n",
    "      # Impute NaNs possibly created by unknown_value in OrdinalEncoder\n",
    "      ('imputer_after_ordinal', SimpleImputer(strategy='most_frequent')), # Or use median if scaling after\n",
    "  ])\n",
    "\n",
    "  # --- Combine pipelines using ColumnTransformer ---\n",
    "  print(f\"Applying numerical transforms to: {num_features}\")\n",
    "  print(f\"Applying nominal categorical transforms to: {cat_nom_features}\")\n",
    "  print(f\"Applying ordinal categorical transforms to: {cat_ord_features}\")\n",
    "\n",
    "  preprocessor = ColumnTransformer(\n",
    "      transformers=[\n",
    "          ('num', numeric_transformer, num_features),\n",
    "          ('cat_nom', categorical_transformer_nominal, cat_nom_features),\n",
    "          ('cat_ord', categorical_transformer_ordinal, cat_ord_features)\n",
    "      ],\n",
    "      remainder='drop' # Drops columns not specified in transformers\n",
    "  )\n",
    "  return preprocessor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".insane_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
